[bucket-crawler]
namespace = OPENIO
user = openio
# Comma separated list of volumes to watch
volume_list = xcute-customer-technical-bucket

# Wait random time before starting
# to avoid all the crawlers from working at the same time.
wait_random_time_before_starting = False
# The crawler stores a marker in a file to be able to resume after being
# stopped/restarted. Default to False.
# use_marker = False
# In seconds, the interval between two full scans. Defaults to half an hour.
interval = 1800
# In seconds, the interval between two logs entries (for each volume)
# Defaults to 300 seconds.
report_interval = 300
# Maximum containers to be scanned per second. Defaults to 10.
scanned_per_second = 10
# Number of chunks to check before updating the markers
# (not used if <use_marker> is disabled). Default to 900.
# This value represents 60s at max rate.
# scanned_between_markers = 900
# Xcute type for jobs created by the crawler
xcute_type = customer
# Avoid creating to many xcute jobs at the same time (max 10k).
# limit_nb_objects_one_pass = 1000

# Common log stuff
log_level = INFO
log_facility = LOG_LOCAL0
log_address = /dev/log
syslog_prefix = OIO,OPENIO,bucket,1

[pipeline:main]
pipeline = logger

[filter:logger]
use = egg:oio#logger
