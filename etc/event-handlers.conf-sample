
[handler:storage.content.new]
pipeline =

[handler:storage.content.update]
pipeline = object_restore_detection

[handler:storage.content.append]
pipeline =

[handler:storage.content.broken]
pipeline = content_rebuild

[handler:storage.content.deleted]
pipeline = content_cleaner

[handler:storage.content.drained]
pipeline = content_cleaner

[handler:storage.container.new]
pipeline = account_update

[handler:storage.container.update]
pipeline = account_update

[handler:storage.container.deleted]
pipeline = account_update

[handler:storage.container.state]
pipeline = account_update

[handler:storage.chunk.new]
pipeline = volume_index

[handler:storage.chunk.deleted]
pipeline = volume_index

[handler:storage.meta2.deleted]
pipeline = volume_index

[handler:account.services]
pipeline = account_update volume_index

# -----------------------------------------------------------------
# For object events: delete chunks
[filter:content_cleaner]
use = egg:oio#content_cleaner
# Allowed parameters:
# - backoff_factor (float, 0),
# - concurrency (int, 3)
# - max_retries (int, 0),
# - pool_connections (int, 32),
# - pool_maxsize (int, 32),
# Timeouts to the rawx service, in seconds
# (if timeout is not defined)
#connection_timeout=1.0
#read_timeout=5.0
#allow_retry=true

# Retry deletion if rawx services report IO errors. Setting this to false
# will consider the chunk is already lost in case of an IO error, and the event
# will be acknowledged (instead of being sent to the deadletter topic).
retry_on_io_error=true

# Time in seconds before an event should be reprocessed
retry_delay = 60

# Factor to apply on the retry delay for serious issues
# (e.g. IO error on rawx)
serious_issue_factor = 60

# -----------------------------------------------------------------
# For container events: update counters inside the account service
[filter:account_update]
use = egg:oio#account_update
# Timeouts to the account service, in seconds
#connection_timeout=2.0
#read_timeout=30.0
# Features to track, comma separated list
#features_whitelist = lifecycle,website

# -----------------------------------------------------------------
# Index meta2 or rawx content into rdir services
[filter:volume_index]
use = egg:oio#volume_index
# Time in seconds before an event should be reprocessed
retry_delay = 60
# Factor to apply on the retry delay for serious issues
# (e.g. no rdir assigned to the volume)
serious_issue_factor = 5

# How to deal with write errors.
# - 0: retry on any error
# - <0: tolerate this number of errors
# - >0: require this number of successes
# Default value is 1: require 1 successful write.
write_quorum = -1


# -----------------------------------------------------------------
# Example of the notify filter: redirect some events to another tube,
# with a filter on the event's URL.
[filter:content_rebuild]
use = egg:oio#notify
tube = oio-rebuild
queue_url = ${QUEUE_URL}
# Exclude events whose URL matches these accounts and containers
exclude = AUTH_demo1,AUTH_demo2/trash
# Kafka endpoint
broker_endpoint = kafka://localhost:19092
topic = oio-rebuild

# -----------------------------------------------------------------
# Spread delete events accross rawx servers
[filter:delete]
use = egg:oio#delete
broker_endpoint = kafka://localhost:19092
topic_prefix = oio-delete-
# Time in seconds before an event should be reprocessed
retry_delay = 60
# Cache duration for rawx services
services_cache_duration = 3600

# -----------------------------------------------------------------
# Spread delete events accross rawx servers
[filter:blob_rebuilder]
use = egg:oio#blob_rebuilder
# Time in seconds before an event should be reprocessed
retry_delay = 60

# -----------------------------------------------------------------
# Retry events
[filter:delay]
use = egg:oio#delay
# Events time to live in seconds (one day).
# After that time, they are sent to the deadletter topic.
events_time_to_live = 86400

# -----------------------------------------------------------------
# Example of the notify filter: redirect some events to another tube,
# with regular expressions on the storage policy.
[filter:notify_delete]
use = egg:oio#notify
queue_url = ${QUEUE_URL}

# Strip some fields from the event.
strip_fields = aliases,contents_headers

# Default tube
tube = oio-delete

# Regex and tube for EC storage policies.
policy_regex_EC = ^EC.*
tube_EC = oio-delete-ec

# Ensure fields are present in events (values are not checked)
required_fields = destinations

# -----------------------------------------------------------------
# Retry events
[filter:mpu_cleaner]
use = egg:oio#mpu_cleaner
# Note that this value should not be higher because deleting too many objects at
# the same time is a high consumer.
object_deletion_concurrency = 100
retry_delay = 60
# Delay when there is some remaining parts for this MPU.
# 0 means the event will be emitted in the same topic again.
retry_delay_remaining_parts = 0
# Event will be retried if the manifest still exists until this timeout is reached.
timeout_manifest_still_exists = 900

# -----------------------------------------------------------------
# Does nothing. You'd better not defining any filter.
[filter:noop]
use = egg:oio#noop

# -----------------------------------------------------------------
# Display the body of each event passing through (for debugging).
[filter:logger]
use = egg:oio#logger
#log_name=logger_filter
#log_format=X-OVH-TOKEN:XXXXXXXXX    topic:%(topic)s    event:%(event)s
#log_format_extra=filter_specific:%(field)s

# -----------------------------------------------------------------
# Bury each event passing through (for debugging).
[filter:bury]
use = egg:oio#bury

# -----------------------------------------------------------------
# Store lifecycle delete events
[filter:lifecycle_delete_backup]
use = egg:oio#lifecycle_delete_backup
field = url.bucket
# Credentials of the backup bucket
backup_account =
backup_bucket =
# Prefix for backups
prefix = /backup-prefix
# Temporary directory
cache_directory = /tmp

# -----------------------------------------------------------------
# Restore lifecycle deleted object
[filter:lifecycle_delete_restore]
use = egg:oio#lifecycle_delete_restore

# -----------------------------------------------------------------
# Move the event from deadletter to the original topic.
[filter:deadletter]
use = egg:oio#deadletter

# Name of the topic where to send events which have been
# retried too many times.
graveyard = "oio-graveyard"

# Maximum number of passes through the deadletter topic
# before the event is sent to the graveyard.
# Set to -1 to never send to the graveyard.
# Set to 0 to always send to the graveyard.
max_deadletter_count = 2

#redirect_event.name = destination_topic
redirect_storage_container_state = oio
redirect_storage_chunk_new = oio-chunk

# -----------------------------------------------------------------
# Emit billing stats for object deleted before minimal storage duration.
[filter:early_delete_detection]
use = egg:oio#early_delete_detection
redis_host = 127.0.0.1:6379
# Minimal storage duration in seconds per storage class
# STANDARD_IA -> 30 days (aka 2592000 seconds)
storage_class_minimal_duration.STANDARD_IA = 2592000
# Storage class mapping
storage_class.GLACIER = SINGLE,TWOCOPIES
storage_class.STANDARD = THREECOPIES,EC


# -----------------------------------------------------------------
# Emit restore events.
[filter:object_restore_detection]
use = egg:oio#object_restore_detection
broker_endpoint = kafka://localhost:19092
topic = oio-archive-restore
