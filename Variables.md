# OpenIO SDS configuration



*This file has been generated by confgen.py*

## Variables for production purposes

### client.errors_cache.enabled

> Should the client feed a cache with the network errors it encounters, and should those errors be used to prevent RPC to be performed toward 'too-faulty' peers.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__CLIENT_ERRORS_CACHE_ENABLED*

### client.errors_cache.max

> Sets the number of faults (on the period given by client.errors_cache.period) beyond which a peer is considered as too faulty to try a new RPC.

 * default: **15**
 * type: guint64
 * cmake directive: *OIO__CLIENT_ERRORS_CACHE_MAX*
 * range: 1 -> 4294967296

### client.errors_cache.period

> Sets the size of the time window used to count the number of network errors.

 * default: **15**
 * type: gint64
 * cmake directive: *OIO__CLIENT_ERRORS_CACHE_PERIOD*
 * range: 1 -> 3600

### core.period.refresh.cpu_idle

> Sets the miniimal amount of time between two refreshed of the known CPU-idle counters for the current host. Keep this value small.

 * default: **1 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__CORE_PERIOD_REFRESH_CPU_IDLE*
 * range: 100 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### core.period.refresh.io_idle

> Sets the minimal amount of time between two refreshes of the known IO-idle counters for the current host. Keep this small.

 * default: **1 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__CORE_PERIOD_REFRESH_IO_IDLE*
 * range: 100 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### core.period.refresh.major_minor

> Sets the minimal amount of time between two refreshes of the list of the major/minor numbers of the known devices, currently mounted on the current host. If the set of mounted file systems doesn't change, keep this value high.

 * default: **30 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__CORE_PERIOD_REFRESH_MAJOR_MINOR*
 * range: 100 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### core.resolver.noshuffle

> In the current oo-sds client SDK, should the directory service be shuffled before accessed. This helps ensuring

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__CORE_RESOLVER_NOSHUFFLE*

### core.sds.autocreate

> In the current oio-sds client SDK, should the entities be autocreated while accessed for the first time. So, when pushing a content in a container, when this option is set to 'true', the USER and the CONTAINER will be created and configured to the namespace's defaults.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__CORE_SDS_AUTOCREATE*

### core.sds.noshuffle

> In the current oio-sds client SDK, should the rawx services be shuffled before accessed. This helps ensuring a little load-balancing on the client side.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__CORE_SDS_NOSHUFFLE*

### events.beanstalkd.delay

> Sets the delay on each notification sent to the BEANSTALK endpoint

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__EVENTS_BEANSTALKD_DELAY*
 * range: 0 -> 86400

### events.beanstalkd.prio

> Sets the priority of each notification sent to the BEANSTALK endpoint

 * default: **2147483648**
 * type: guint
 * cmake directive: *OIO__EVENTS_BEANSTALKD_PRIO*
 * range: 0 -> 2147483648

### events.beanstalkd.ttr

> Sets the TTR (time to run) allow on the treatment of the notificatio sent to the beanstalkd

 * default: **120**
 * type: gint64
 * cmake directive: *OIO__EVENTS_BEANSTALKD_TTR*
 * range: 0 -> 86400

### events.common.pending.delay

> Sets the buffering delay of the events emitted by the application

 * default: **5 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__EVENTS_COMMON_PENDING_DELAY*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### events.common.pending.max

> Sets the maximum number of pending events, not received yet by the endpoint

 * default: **1000**
 * type: guint32
 * cmake directive: *OIO__EVENTS_COMMON_PENDING_MAX*
 * range: 1 -> 1048576

### events.zmq.max_recv

> Sets the maximum number of ACK managed by the ZMQ notification client

 * default: **32**
 * type: guint
 * cmake directive: *OIO__EVENTS_ZMQ_MAX_RECV*
 * range: 1 -> 1073741824

### gridd.timeout.connect.common

> Sets the connection timeout, involved in any RPC to a 'meta' service.

 * default: **2.0**
 * type: gdouble
 * cmake directive: *OIO__GRIDD_TIMEOUT_CONNECT_COMMON*
 * range: 0.01 -> 120.0

### gridd.timeout.single.common

> Sets the default timeout for unitary (request/response) RPC, without considering the possible redirection.

 * default: **30.0**
 * type: gdouble
 * cmake directive: *OIO__GRIDD_TIMEOUT_SINGLE_COMMON*
 * range: 0.01 -> 120.0

### gridd.timeout.whole.common

> Sets the global timeout of a RPC to e 'meta' service, considering all the possible redirections.

 * default: **30.0**
 * type: gdouble
 * cmake directive: *OIO__GRIDD_TIMEOUT_WHOLE_COMMON*
 * range: 0.01 -> 120.0

### malloc.trim_size.ondemand

> Sets how many bytes bytes are released when the LEAN request is received by the current 'meta' service.

 * default: **0**
 * type: guint
 * cmake directive: *OIO__MALLOC_TRIM_SIZE_ONDEMAND*
 * range: 0 -> 2147483648

### malloc.trim_size.periodic

> Sets how many bytes bytes are released when the LEAN request is received by the current 'meta' service.

 * default: **0**
 * type: guint
 * cmake directive: *OIO__MALLOC_TRIM_SIZE_PERIODIC*
 * range: 0 -> 2147483648

### meta0.outgoing.timeout.common.req

> Sets the timeout to the set of (quick) RPC that query a meta0 service

 * default: **10.0**
 * type: gdouble
 * cmake directive: *OIO__META0_OUTGOING_TIMEOUT_COMMON_REQ*
 * range: 0.01 -> 60.0

### meta2.batch.maxlen

> When listing a container, limits the number of items to that value.

 * default: **1000**
 * type: guint
 * cmake directive: *OIO__META2_BATCH_MAXLEN*
 * range: 1 -> 100000

### meta2.generate.precheck

> Should the meta2 check the container state (quota, etc) before generating chunks.

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__META2_GENERATE_PRECHECK*

### meta2.reload.lb.period

> Sets the period of the periodical reloading of the Load-balancing state, in the current meta2 service.

 * default: **10**
 * type: gint64
 * cmake directive: *OIO__META2_RELOAD_LB_PERIOD*
 * range: 1 -> 3600

### meta2.reload.nsinfo.period

> Sets the period of the periodical reloading of the namespace configuration, in the current meta2 service.

 * default: **5**
 * type: gint64
 * cmake directive: *OIO__META2_RELOAD_NSINFO_PERIOD*
 * range: 1 -> 3600

### proxy.bulk.max.create_many

> In a proxy, sets how many containers can be created at once.

 * default: **100**
 * type: guint
 * cmake directive: *OIO__PROXY_BULK_MAX_CREATE_MANY*
 * range: 0 -> 10000

### proxy.cache.directory.max

> In a proxy, sets how many directory entries the resolver may keep

 * default: **1048576**
 * type: guint
 * cmake directive: *OIO__PROXY_CACHE_DIRECTORY_MAX*
 * range: 0 -> 4194304

### proxy.cache.directory.ttl

> In a proxy, sets how long the resolver keeps directory entries

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__PROXY_CACHE_DIRECTORY_TTL*
 * range: 0 -> 7 * G_TIME_SPAN_DAY

### proxy.cache.enabled

> In a proxy, sets if any form of caching is allowed

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_CACHE_ENABLED*

### proxy.cache.services.max

> In a proxy, sets how many service entries the resolver might keep.

 * default: **1048576**
 * type: guint
 * cmake directive: *OIO__PROXY_CACHE_SERVICES_MAX*
 * range: 0 -> 4194304

### proxy.cache.services.ttl

> In a proxy, sets how long the resolver keeps service entries

 * default: **1 * G_TIME_SPAN_HOUR**
 * type: gint64
 * cmake directive: *OIO__PROXY_CACHE_SERVICES_TTL*
 * range: 0 -> 7 * G_TIME_SPAN_DAY

### proxy.force.master

> In a proxy, should the process ask the target service (with the help of an option in each RPC) to accept the RPC only if it is MASTER on that DB.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_FORCE_MASTER*

### proxy.outgoing.timeout.common

> In a proxy, sets the global timeout for all the other RPC issued (not conscience, not stats-related)

 * default: **30.0**
 * type: gdouble
 * cmake directive: *OIO__PROXY_OUTGOING_TIMEOUT_COMMON*
 * range: 0.01 -> 60.0

### proxy.outgoing.timeout.conscience

> In a proxy, sets the global timeout for the RPC to the central cosnience service.

 * default: **2.0**
 * type: gdouble
 * cmake directive: *OIO__PROXY_OUTGOING_TIMEOUT_CONSCIENCE*
 * range: 0.01 -> 60.0

### proxy.outgoing.timeout.stat

> In a proxy, sets the global timeout for 'stat' requests issued (mostly forwarded for the event-agent)

 * default: **5.0**
 * type: gdouble
 * cmake directive: *OIO__PROXY_OUTGOING_TIMEOUT_STAT*
 * range: 0.01 -> 60.0

### proxy.period.cs.downstream

> In a proxy, sets the period between the refreshes of the load-balancing state from the central conscience.

 * default: **5**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_CS_DOWNSTREAM*
 * range: 0 -> 60

### proxy.period.cs.upstream

> In a proxy, sets the period between two sendings of services states to the conscience.

 * default: **1**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_CS_UPSTREAM*
 * range: 1 -> 60

### proxy.period.refresh.csurl

> In the proxy, tells the period between the reloadings of the conscience URL, known from the local configuration

 * default: **30**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_REFRESH_CSURL*
 * range: 0 -> 86400

### proxy.period.refresh.srvtypes

> In the proxy, tells the period between two refreshes of the known service types, from the conscience

 * default: **30**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_REFRESH_SRVTYPES*
 * range: 1 -> 86400

### proxy.period.reload.meta0

> In the proxy, tells the period betweenthe refreshed of the meta0 cache

 * default: **30**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_RELOAD_META0*
 * range: 1 -> 86400

### proxy.period.reload.nsinfo

> In the proxy, tells the period between two refreshes of the namespace configuration, from the conscience

 * default: **30**
 * type: gint64
 * cmake directive: *OIO__PROXY_PERIOD_RELOAD_NSINFO*
 * range: 1 -> 3600

### proxy.prefer.master_for_read

> In a proxy, upon a read request, should the proxy prefer a service known to host a MASTER copy of the DB. Supersedes proxy.prefer.slave_for_read

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_PREFER_MASTER_FOR_READ*

### proxy.prefer.master_for_write

> In a proxy, upon a write request, should the proxy prefer services known to host the MASTER copy of the DB 

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_PREFER_MASTER_FOR_WRITE*

### proxy.prefer.slave_for_read

> In a proxy, upon a read request, should the proxy prefer a service known to host a SLAVE copy of the DB.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_PREFER_SLAVE_FOR_READ*

### proxy.quirk.local_scores

> In a proxy, tells if the (ugly-as-hell) quirk that sets the score known from the conscience on the corresponding entries in the cache of services 'known to be local'

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__PROXY_QUIRK_LOCAL_SCORES*

### proxy.ttl.services.down

> In the proxy cache, sets the TTL of a service known to be down

 * default: **5 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__PROXY_TTL_SERVICES_DOWN*
 * range: 0 -> 1 * G_TIME_SPAN_DAY

### proxy.ttl.services.known

> In a proxy, sets the TTL of each service already encountered

 * default: **5 * G_TIME_SPAN_DAY**
 * type: gint64
 * cmake directive: *OIO__PROXY_TTL_SERVICES_KNOWN*
 * range: 0 -> 7 * G_TIME_SPAN_DAY

### proxy.ttl.services.local

> In the proxy cache, sets the TTL of a local service

 * default: **30 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__PROXY_TTL_SERVICES_LOCAL*
 * range: 0 -> 1 * G_TIME_SPAN_DAY

### proxy.ttl.services.master

> In a proxy, sets the TTL on each 'known master' entry. That cache is filled each time a redirection to a MASTER occurs, so that we can immediately direct write operation to the service that owns the MASTER copy.

 * default: **5 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__PROXY_TTL_SERVICES_MASTER*
 * range: 0 -> 7 * G_TIME_SPAN_DAY

### proxy.url.path.maxlen

> In a proxy, sets the maximum length for the URL it receives. This options protects stack allocation for that URL.

 * default: **2048**
 * type: guint
 * cmake directive: *OIO__PROXY_URL_PATH_MAXLEN*
 * range: 32 -> 65536

### resolver.cache.csm0.max.default

> In any service resolver instanciated, sets the maximum number of entries related to meta0 (meta1 addresses) and conscience (meta0 address)

 * default: **0**
 * type: guint
 * cmake directive: *OIO__RESOLVER_CACHE_CSM0_MAX_DEFAULT*
 * range: 0 -> 4194304

### resolver.cache.csm0.ttl.default

> In any service resolver instanciated, sets the default TTL on the entries related meta0 (meta1 addresses) and conscience (meta0 address)

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__RESOLVER_CACHE_CSM0_TTL_DEFAULT*
 * range: 0 -> 4Mi

### resolver.cache.srv.max.default

> In any service resolver instanciated, sets the maximum number of meta1 entries (data-bound services)

 * default: **0**
 * type: guint
 * cmake directive: *OIO__RESOLVER_CACHE_SRV_MAX_DEFAULT*
 * range: 0 -> 1048576

### resolver.cache.srv.ttl.default

> In any service resolver instanciated, sets the default TTL on the meta1 entries (data-bound services)

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__RESOLVER_CACHE_SRV_TTL_DEFAULT*
 * range: 0 -> 4Mi

### server.batch.accept

> In the network core, when the server socket wakes the call to epoll_wait(), that value sets the number of subsequent calls to accept(). Setting it to a low value allows to quickly switch to other events (established connection) and can lead to a strvation on the new connections. Setting to a high value might spend too much time in accepting and ease denials of service (with established but idle cnx).

 * default: **64**
 * type: guint
 * cmake directive: *OIO__SERVER_BATCH_ACCEPT*
 * range: 1 -> 4096

### server.batch.events

> In the network core of a server, how many events do you manage in each call to epoll_wait(). Set to a low value to quickly react on new connections, to an higher value to rather treat established connections. The value is bound to a stack-allocated buffer, keep it rather small.

 * default: **128**
 * type: guint
 * cmake directive: *OIO__SERVER_BATCH_EVENTS*
 * range: 1 -> 4096

### server.cnx.timeout.idle

> In the current server, sets the maximumu amount of time a connection may live without activity since the last activity (i.e. the last reply sent)

 * default: **5 * G_TIME_SPAN_MINUTE**
 * type: gint64
 * cmake directive: *OIO__SERVER_CNX_TIMEOUT_IDLE*
 * range: 0 -> 1 * G_TIME_SPAN_DAY

### server.cnx.timeout.never

> In the current server, sets the maximum amount of time an established connection is allowed to live when it has no activity at all.

 * default: **30 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SERVER_CNX_TIMEOUT_NEVER*
 * range: 0 -> 1 * G_TIME_SPAN_DAY

### server.cnx.timeout.persist

> In the current server, sets the maximum amount of time a connection is allowed to live, since its creation by the accept() call, wheter it presents activity or not.

 * default: **2 * G_TIME_SPAN_HOUR**
 * type: gint64
 * cmake directive: *OIO__SERVER_CNX_TIMEOUT_PERSIST*
 * range: 0 -> 1 * G_TIME_SPAN_DAY

### server.pool.max_idle

> In the current server, sets how long a thread can remain unused before considered as idle (and thus to be stopped)

 * default: **30 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SERVER_POOL_MAX_IDLE*
 * range: 1 -> 1 * G_TIME_SPAN_HOUR

### server.pool.max_stat

> In the current server, sets how many threads are allowed to the stats server. Keep this value really small, 1 should be enough for most usages, and consider increasing it if you have clues that the management of internal metrics is the bottleneck.

 * default: **1**
 * type: gint
 * cmake directive: *OIO__SERVER_POOL_MAX_STAT*
 * range: 1 -> 1073741824

### server.pool.max_udp

> In the current server, sets the maximum number of threads for pool responsible for the UDP messages handling. UDP is only used for quick synchronisation messages during MASTER elections

 * default: **8**
 * type: gint
 * cmake directive: *OIO__SERVER_POOL_MAX_UDP*
 * range: 1 -> 1073741824

### server.pool.max_unused

> In the current server, sets how many threads may remain unused. This value is, in the GLib, common to all the threadpools.

 * default: **20**
 * type: gint
 * cmake directive: *OIO__SERVER_POOL_MAX_UNUSED*
 * range: 0 -> 1073741824

### server.pool.max_workers

> In the current server, sets the maximum number of threads for the pool responsible for the TCP connections (threading model is one thread per request being managed, and one request at once per TCP connection)

 * default: **-1**
 * type: gint
 * cmake directive: *OIO__SERVER_POOL_MAX_WORKERS*
 * range: -1 -> 1073741824

### server.udp_queue.max

> In the current server, sets the maximumu length of the queue for UDP messages. When that number has been reached and a new message arrives, the message will be dropped.

 * default: **8192**
 * type: guint
 * cmake directive: *OIO__SERVER_UDP_QUEUE_MAX*
 * range: 0 -> 2147483648

### server.udp_queue.ttl

> In the current server, sets the maximum amount of time a queued UDP frame may remain in the queue. When unqueued, if the message was queued for too long, it will be dropped. The purpose of such a mechanism is to avoid clogging the queue and the whole election/cache mechanisms with old messages, thoses message having already been resent.

 * default: **2 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SERVER_UDP_QUEUE_TTL*
 * range: 100 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_DAY

### socket.linger.delay

> When socket.linger.enabled is set to TRUE, socket.linger.delat tells how the socket remains in the TIME_WAIT state after the close() has been called.

 * default: **1**
 * type: gint64
 * cmake directive: *OIO__SOCKET_LINGER_DELAY*
 * range: 0 -> 60

### socket.linger.enabled

> Set to TRUE to allow the LINGER behavior of TCP sockets, as a default. The connections then end with a normal FIN packet, and go in the TIME_WAIT state for a given delay. Setting to FALSE causes connections to be closed with a RST packet, then avoiding a lot of TCP sockets in the TIME_WAIT state.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__SOCKET_LINGER_ENABLED*

### socket.nodelay.enabled

> Should the socket to meta~ services receive the TCP_NODELAY flag. When TRUE, it disables the Naggle's algorithm.

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__SOCKET_NODELAY_ENABLED*

### socket.quickack.enabled

> Should the sockets opened by the application receive the TCP_QUICKACK flag.

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__SOCKET_QUICKACK_ENABLED*

### sqliterepo.cache.heavyload.alert

> Triggers an alert when a thread tries to wait for an overloaded database.

 * default: **TRUE**
 * type: gboolean
 * cmake directive: *OIO__SQLITEREPO_CACHE_HEAVYLOAD_ALERT*

### sqliterepo.cache.heavyload.fail

> Triggers an error when a thread waits for an overloaded database.

 * default: **FALSE**
 * type: gboolean
 * cmake directive: *OIO__SQLITEREPO_CACHE_HEAVYLOAD_FAIL*

### sqliterepo.cache.timeout.lock

> Sets how long we (unit)wait on the lock around the databases. Keep it small.

 * default: **1 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_CACHE_TIMEOUT_LOCK*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.cache.timeout.open

> Sets how long a worker thread accepts for a DB to become available.

 * default: **20 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_CACHE_TIMEOUT_OPEN*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_DAY

### sqliterepo.cache.ttl.cool

> Sets the period after the return to the IDLE/COLD state, during which the recycling is forbidden

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_CACHE_TTL_COOL*
 * range: 0 -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.cache.ttl.hot

> Sets the period after the return to the IDLE/HOT state, during which the recycling is forbidden

 * default: **0**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_CACHE_TTL_HOT*
 * range: 0 -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.cache.waiting.max

> Sets how many threads can wait on a single database. All the additional waiters will be denied with any wait attempt.

 * default: **16**
 * type: guint32
 * cmake directive: *OIO__SQLITEREPO_CACHE_WAITING_MAX*
 * range: 0 -> 2147483648

### sqliterepo.client.timeout.alert_if_longer

> In the current sqliterepo repository, sets the maximum amount of time a periodical task may take, while checking for the timeouts on the outbound connections.

 * default: **5 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_CLIENT_TIMEOUT_ALERT_IF_LONGER*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.election.delay.expire_master

> In the current sqliterepo repository, sets the amount of time after which a MASTER election will drop its status and return to the NONE status. This helps recycling established-but-unused elections, and save Zookeeper nodes. Keep this value between sqliterepo.election.delay.expire_slave and sqliterepo.election.delay.expire_slave + sqliterepo.election.delay.ping_final.

 * default: **25 * G_TIME_SPAN_MINUTE**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_DELAY_EXPIRE_MASTER*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 7 * G_TIME_SPAN_DAY

### sqliterepo.election.delay.expire_none

> In the current sqliterepo repository, sets the amount of time an election without status will be forgotten 

 * default: **5 * G_TIME_SPAN_MINUTE**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_DELAY_EXPIRE_NONE*
 * range: 1 * G_TIME_SPAN_SECOND -> 1 * G_TIME_SPAN_DAY

### sqliterepo.election.delay.expire_slave

> In the current sqliterepo repository, sets the amount of time after which a SLAVE election will drop its status and return to the NONE status. This helps recycling established-but-unused elections, and save Zookeeper nodes.

 * default: **15 * G_TIME_SPAN_MINUTE**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_DELAY_EXPIRE_SLAVE*
 * range: 1 * G_TIME_SPAN_SECOND -> 7 * G_TIME_SPAN_DAY

### sqliterepo.election.delay.ping_final

> In the current sqliterepo repository, sets the average amount of time after which a PING will be sent for an established election. This is an average, in facts a jitter is introduced to avoid resonance effects on large-scale platforms.

 * default: **15 * G_TIME_SPAN_MINUTE**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_DELAY_PING_FINAL*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_DAY

### sqliterepo.election.delay.retry_failed

> In the current sqliterepo repository, sets the amount of time after which a failed election leaves its FAILED status and returns to the NONE status.

 * default: **2 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_DELAY_RETRY_FAILED*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 7 * G_TIME_SPAN_DAY

### sqliterepo.election.nowait.after

> In the current sqliterepo repository, sets the amount of time spent in an election resolution that will make a worker thread won't wait at all an consider that election is stalled.

 * default: **15 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_NOWAIT_AFTER*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.election.task.expire_max_per_round

> Sets how many elections can be expired during the periodical expiration task.

 * default: **100**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_ELECTION_TASK_EXPIRE_MAX_PER_ROUND*
 * range: 1 -> 2147483648

### sqliterepo.election.wait.delay

> In the current sqliterepo repository, sets the maximum amount of time a worker thread is allowed to wait for an election to get its final status.

 * default: **5 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_WAIT_DELAY*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.election.wait.quantum

> In the current sqliterepo repository, while loop-waiting for a final election status to be reached, this value sets the unit amount of time of eacch unit wait on the lock. Keep this value rather small to avoid waitin for too long, but not too small to avoid dumping CPU cycles in active waiting.

 * default: **1 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_ELECTION_WAIT_QUANTUM*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.heat.threshold

> Sets the heat value below which a databse is considered hot

 * default: **1**
 * type: guint32
 * cmake directive: *OIO__SQLITEREPO_HEAT_THRESHOLD*
 * range: 1 -> 2147483648

### sqliterepo.outgoing.timeout.cnx.getvers

> Sets the connection timeout when exchanging versions between databases replicas.

 * default: **0.5**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_CNX_GETVERS*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.cnx.replicate

> Sets the connection timeout sending a replication request.

 * default: **1.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_CNX_REPLICATE*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.cnx.resync

> Set the connection timeout during RPC to ask for a SLAVE database to be resync on its MASTER

 * default: **1.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_CNX_RESYNC*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.cnx.use

> Sets the connection timeout when ping'ing a peer database. Keep it small. Only used when UDP is disabled.

 * default: **0.25**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_CNX_USE*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.req.getvers

> Sets the global timeout when performing a version exchange RPC. Keep it rather small, to let election quickly fail on network troubles. Only used when UDP is disabled.

 * default: **2.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_REQ_GETVERS*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.req.replicate

> Sets the global timeout when sending a replication RPC, from the current MASTER to a SLAVE

 * default: **10.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_REQ_REPLICATE*
 * range: 0.01 -> 30.0

### sqliterepo.outgoing.timeout.req.resync

> Sets the global timeout of a RESYNC request sent to a 'meta' service. Sent to a SLAVE DB, the RESYNC operation involves a RPC from the SLAVE to the MASTER, then a DB dump on the MASTER and restoration on the SLAVE. Thus that operation might be rather long, due to the possibility of network/disk latency/bandwidth, etc.

 * default: **30.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_REQ_RESYNC*
 * range: 0.01 -> 60.0

### sqliterepo.outgoing.timeout.req.use

> Sets the global timeout when ping'ing a peer database. Keep it small.

 * default: **1.0**
 * type: gdouble
 * cmake directive: *OIO__SQLITEREPO_OUTGOING_TIMEOUT_REQ_USE*
 * range: 0.01 -> 30.0

### sqliterepo.page_size

> In the current sqliterepo repository, sets the page size of all the databases used. This value only has effects on databases created with that value.

 * default: **4096**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_PAGE_SIZE*
 * range: 512 -> 1048576

### sqliterepo.release_size

> Sets how many bytes bytes are released when the LEAN request is received by the current 'meta' service.

 * default: **67108864**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_RELEASE_SIZE*
 * range: 1 -> 2147483648

### sqliterepo.repo.getvers_max_retries

> Sets how many versions exchanges are allowed during the journey in the election FSM.

 * default: **2**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_REPO_GETVERS_MAX_RETRIES*
 * range: 1 -> 64

### sqliterepo.repo.max_bases

> Sets how many databases can be kept simultaneously open in the current service.

 * default: **32768**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_REPO_MAX_BASES*
 * range: 8 -> 131072

### sqliterepo.service.exit_ttl

> .

 * default: **10 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_SERVICE_EXIT_TTL*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.timeout.zk

> Sets the timeout of the zookeeper handle (in the meaning of the zookeeper client library)

 * default: **10 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__SQLITEREPO_TIMEOUT_ZK*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_HOUR

### sqliterepo.zk.rrd.threshold

> Sets the maximum number of reconnections to the ZK that remains acceptable. Beyond that limit, we consider the current service has been disconnected, and that it loast all its nodes.

 * default: **5**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_ZK_RRD_THRESHOLD*
 * range: 1 -> 2147483648

### sqliterepo.zk.rrd.window

> Sets the time window to remember the reconnection events, on a ZK connection.

 * default: **5**
 * type: guint
 * cmake directive: *OIO__SQLITEREPO_ZK_RRD_WINDOW*
 * range: 1 -> 4095

### sqlx.outgoing.timeout.req

> Sets the timeout for the requests issued to the SQLX services.

 * default: **30.0**
 * type: gdouble
 * cmake directive: *OIO__SQLX_OUTGOING_TIMEOUT_REQ*
 * range: 0.01 -> 60.0

## Variables only for testing purposes

These variables are only active when the **ENBUG** option has been specified on
the cmake command line.


### enbug.client.fake_timeout.threshold

> Set the probability of fake timeout failures, in any client RPC to a 'meta' service

 * default: **10**
 * type: gint32
 * cmake directive: *OIO__ENBUG_CLIENT_FAKE_TIMEOUT_THRESHOLD*
 * range: 0 -> 0

### enbug.sqliterepo.client.failure.threshold

> In testing situations, sets the average ratio of requests failing for a fake reason (from the peer). This helps testing the retrial mechanisms.

 * default: **10**
 * type: gint32
 * cmake directive: *OIO__ENBUG_SQLITEREPO_CLIENT_FAILURE_THRESHOLD*
 * range: 0 -> 100

### enbug.sqliterepo.client.timeout.period

> In testing situations, sets the average ratio of requests failing for a fake reason (connection timeout). This helps testing the retrial mechanisms and the behavior under strong network split-brain.

 * default: **1 * G_TIME_SPAN_SECOND**
 * type: gint64
 * cmake directive: *OIO__ENBUG_SQLITEREPO_CLIENT_TIMEOUT_PERIOD*
 * range: 1 * G_TIME_SPAN_MILLISECOND -> 1 * G_TIME_SPAN_DAY

### enbug.sqliterepo.synchro.failure

> Fake Error rate on synchronism RPC (a.k.a. ZK) 

 * default: **10**
 * type: gint32
 * cmake directive: *OIO__ENBUG_SQLITEREPO_SYNCHRO_FAILURE*
 * range: 0 -> 100
